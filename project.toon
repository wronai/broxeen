# broxeen | 49f 6310L | python:3/typescript:35/javascript:3/rust:8
# Keys: M=modules, D=details, i=imports, c=classes, f=functions, m=methods
M[49]:
  phonetic.py,73
  vite.config.ts,35
  tailwind.config.js,23
  resolver.py,102
  postcss.config.js,6
  test_phonetic.py,67
  src-tauri/build.rs,3
  src-tauri/test_read.rs,16
  TODO/llm.rs,71
  TODO/llmPrompts.ts,47
  TODO/useLlm.ts,144
  TODO/llmClient.ts,189
  TODO/llmClient.test.ts,124
  src/main.tsx,28
  src/App.tsx,113
  src/vite-env.d.ts,0
  test/broxeen.test.js,5
  src/lib/phonetic.test.ts,105
  src/lib/browseGateway.ts,224
  src/lib/browseGateway.test.ts,140
  src/lib/llmPrompts.ts,47
  src/lib/logger.ts,74
  src/lib/resolver.ts,160
  src/lib/llmClient.ts,189
  src/lib/phonetic.ts,69
  src/lib/runtime.ts,3
  src/lib/resolver.test.ts,108
  src/lib/llmClient.test.ts,124
  src/hooks/useTts.ts,162
  src/hooks/useSpeech.test.ts,224
  src/hooks/useTts.test.ts,169
  src/hooks/useLlm.ts,144
  src/hooks/useSpeech.ts,201
  src/components/Chat.test.tsx,477
  src/components/Settings.test.tsx,215
  src/components/Settings.tsx,253
  src/components/Chat.tsx,387
  src/components/TtsControls.tsx,84
  src/components/TtsControls.test.tsx,85
  src/domain/audioSettings.ts,29
  src/domain/chatEvents.ts,44
  src/domain/chatEvents.test.ts,78
  src/domain/audioSettings.test.ts,31
  src/test/setup.ts,50
  src-tauri/src/llm.rs,71
  src-tauri/src/main.rs,298
  src-tauri/src/test_read.rs,16
  src-tauri/tests/placeholder_test.rs,7
  src-tauri/tests/test_read.rs,17
D:
  phonetic.py:
    i: re
    e: PHONETIC_RULES,_SORTED_RULES,normalize,looks_like_url
    normalize(text:str)->str
    looks_like_url(text:str)->bool
  resolver.py:
    i: re,dataclasses.{dataclass,field},difflib.SequenceMatcher,domains.KNOWN_DOMAINS,phonetic.{looks_like_url,normalize},urllib.parse.quote_plus
    e: ResolveResult,fuzzy_match_domain,resolve
    ResolveResult:   # Result of URL resolution.
    fuzzy_match_domain(input_str:str;threshold:float=0.55;max_results:int=6)->list[tuple[str, float]]
    resolve(raw_input:str;threshold:float=0.55)->ResolveResult
  test_phonetic.py:
    i: pytest,app.phonetic.{looks_like_url,normalize}
    e: TestNormalize,TestLooksLikeUrl
    TestNormalize: test_polish_domains(2),test_international_domains(2),test_separators(2),test_direct_url_passthrough(0),test_double_dot_cleanup(0)  # Test speech-to-URL normalization.
    TestLooksLikeUrl: test_valid_urls(1),test_not_urls(1)  # Test URL detection heuristic.
  src-tauri/build.rs:
    e: main
    main()
  src-tauri/test_read.rs:
    i: std::io::Cursor,url::Url
    e: main
    main()
  TODO/llm.rs:
    i: serde::{Deserialize, Serialize},std::env
    e: LlmResponse
    LlmResponse: 
  TODO/llmPrompts.ts:
    e: getPrompt,PromptMode
    getPrompt(mode: PromptMode;override?)->string
  TODO/useLlm.ts:
    i: react,..{/lib/llmClient,/lib/llmPrompts,/lib/logger}
    e: useLlm,UseLlmOptions,IntentType,UseLlmReturn
    useLlm(options: UseLlmOptions)->UseLlmReturn
  TODO/llmClient.ts:
    i: .{/logger,/runtime}
    e: getConfig,chatDirect,LlmMessage,LlmResponse,chatViaTauri,describeImage,summarizeForTts,chat
    getConfig()->LlmConfig
    chat(messages: LlmMessage[];configOverride?)->Promise<LlmResponse>
    chatDirect(messages: LlmMessage[];cfg: LlmConfig)->Promise<LlmResponse>
    chatViaTauri(messages: LlmMessage[];cfg: LlmConfig)->Promise<LlmResponse>
    askAboutContent(pageContent: string;question: string)->Promise<string>
    describeImage(base64Image: string;mimeType;prompt)->Promise<string>
    summarizeForTts(pageContent: string;maxSentences)->Promise<string>
    detectIntent(userText: string)->Promise<string>
  TODO/llmClient.test.ts:
    i: vitest
    e: mockFetchSuccess,mockFetchError
    mockFetchSuccess(responseText: string;model)
    mockFetchError(status: number;body: string)
  src/App.tsx:
    i: react,@tauri-apps/api/core,lucide-react,.{/components/Chat,/components/Settings,/domain/audioSettings,/lib/logger,/lib/runtime}
    e: App
    App()
  src/lib/browseGateway.ts:
    i: @tauri-apps/api/core,.{/logger,/runtime}
    e: looksLikeHtml,browseInBrowser,normalizeText,AllOriginsResponse,normalizeBrowseResult,BrowseResult,extractBrowserReadableContent,executeBrowseCommand
    normalizeText(text: string)->string
    extractBrowserReadableContent(rawHtml: string)->{ title: string; content: string }
    looksLikeHtml(text: string)->boolean
    normalizeBrowseResult(result: BrowseResult;source: "tauri" | "browser";requestedUrl?)->BrowseResult
    browseInBrowser(url: string)->Promise<BrowseResult>
    executeBrowseCommand(url: string;runtimeIsTauri: boolean)->Promise<BrowseResult>
  src/lib/llmPrompts.ts:
    e: getPrompt,PromptMode
    getPrompt(mode: PromptMode;override?)->string
  src/lib/logger.ts:
    e: ScopedLogger,emit,logAsyncDecorator,LogLevel,logSyncDecorator,createScopedLogger,LogMethod
    emit(level: LogLevel;scope: string | undefined;message: string)
    createScopedLogger(scope?)
    logSyncDecorator(scope: string;operationName: string;fn: (...args: TArgs) => TResult)->(...args: TArgs) => TResult
    logAsyncDecorator(scope: string;operationName: string;fn: (...args: TArgs) => Promise<TResult>)->(...args: TArgs) => Promise<TResult>
  src/lib/resolver.ts:
    i: .{/logger,/phonetic}
    e: resolve,levenshtein,fuzzyMatchDomain,similarity,ResolveResult
    levenshtein(a: string;b: string)->number
    similarity(a: string;b: string)->number
    fuzzyMatchDomain(input: string;threshold;maxResults)->Array<[string, number]>
    resolve(rawInput: string;threshold)->ResolveResult
  src/lib/llmClient.ts:
    i: .{/logger,/runtime}
    e: getConfig,chatDirect,LlmMessage,LlmResponse,chatViaTauri,describeImage,summarizeForTts,chat
    getConfig()->LlmConfig
    chat(messages: LlmMessage[];configOverride?)->Promise<LlmResponse>
    chatDirect(messages: LlmMessage[];cfg: LlmConfig)->Promise<LlmResponse>
    chatViaTauri(messages: LlmMessage[];cfg: LlmConfig)->Promise<LlmResponse>
    askAboutContent(pageContent: string;question: string)->Promise<string>
    describeImage(base64Image: string;mimeType;prompt)->Promise<string>
    summarizeForTts(pageContent: string;maxSentences)->Promise<string>
    detectIntent(userText: string)->Promise<string>
  src/lib/phonetic.ts:
    i: ./logger
    e: normalize,looksLikeUrl
    normalize(text: string)->string
    looksLikeUrl(text: string)->boolean
  src/lib/runtime.ts:
    e: isTauriRuntime
    isTauriRuntime()->boolean
  src/lib/llmClient.test.ts:
    i: vitest
    e: mockFetchSuccess,mockFetchError
    mockFetchSuccess(responseText: string;model)
    mockFetchError(status: number;body: string)
  src/hooks/useTts.ts:
    i: react,../lib/logger
    e: TtsOptions,useTts,preprocessForTts
    preprocessForTts(text: string)->string
    useTts(options: Partial<TtsOptions>)
  src/hooks/useSpeech.test.ts:
    i: vitest,@testing-library/react,./useSpeech
    e: MockRecognition
    makeMockRecognition()
  src/hooks/useLlm.ts:
    i: react,..{/lib/llmClient,/lib/llmPrompts,/lib/logger}
    e: useLlm,UseLlmOptions,IntentType,UseLlmReturn
    useLlm(options: UseLlmOptions)->UseLlmReturn
  src/hooks/useSpeech.ts:
    i: react,..{/lib/logger,/lib/runtime}
    e: getUnsupportedReason,SpeechRecognitionEvent,SpeechRecognitionErrorEvent,useSpeech,SpeechRecognitionInstance,getSpeechRecognitionCtor
    getSpeechRecognitionCtor()->(new () => SpeechRecognitionInstance) | undefined
    getUnsupportedReason(supported: boolean;runtimeIsTauri: boolean)->string | null
    useSpeech(lang: string)
  src/components/Chat.test.tsx:
    i: vitest,@testing-library/react,@tauri-apps/api/core,./Chat
    mockTauriEnvironment()
  src/components/Settings.tsx:
    i: react,@tauri-apps/api/core,lucide-react,..{/domain/audioSettings,/lib/logger}
    e: SettingsProps
    update(partial: Partial<AudioSettings>)
    handleSave()
  src/components/Chat.tsx:
    i: react,lucide-react,./TtsControls,.
    e: ChatProps
    applyEvent(event: ChatEvent)
    addMessage(msg: Omit<ChatMessage; "id">)
    updateMessage(id: number;updates: Partial<ChatMessage>)
    handleSubmit(text?)
    handleLlmQuestion(question: string)
    handleSuggestionClick(url: string)
    handleKeyDown(e: React.KeyboardEvent)
    toggleMic()
  src/components/TtsControls.tsx:
    i: lucide-react,../lib/logger
    e: TtsControlsProps
    handleSpeak()
    handlePause()
    handleResume()
    handleStop()
  src/domain/audioSettings.ts:
    e: AudioSettings,withAudioSettingsDefaults
    withAudioSettingsDefaults(partial: Partial<AudioSettings>)->AudioSettings
  src/domain/chatEvents.ts:
    e: ChatMessageRole,projectChatMessages,ChatMessage,ChatEvent
    projectChatMessages(current: ChatMessage[];event: ChatEvent)->ChatMessage[]
  src-tauri/src/llm.rs:
    i: serde::{Deserialize, Serialize},std::env
    e: LlmResponse
    LlmResponse: 
  src-tauri/src/main.rs:
    i: serde::{Deserialize, Serialize},std::fs,std::path::PathBuf
    e: AudioSettings,BrowseResult,backend_info,backend_warn,backend_error,truncate_to_chars,settings_path,get_settings
    AudioSettings: 
    BrowseResult: 
    backend_info(message: impl AsRef<str>)
    backend_warn(message: impl AsRef<str>)
    backend_error(message: impl AsRef<str>)
    truncate_to_chars(text: &str;max_chars: usize)->String
    settings_path()->PathBuf
    get_settings()->AudioSettings
    save_settings(settings: AudioSettings)->Result<(),
    extract_content(document: &scraper::Html)->String
  src-tauri/src/test_read.rs:
    i: std::io::Cursor,url::Url
    e: main
    main()
  src-tauri/tests/test_read.rs:
    i: url::Url,std::io::Cursor
    e: test_extractor
    test_extractor()