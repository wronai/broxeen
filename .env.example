# ── Broxeen Configuration ────────────────────────────
# Copy to .env and fill in your values.
# All values are also configurable at runtime via the chat UI:
#   type "konfiguracja" or "settings" in the chat.
#
# Get your API key at: https://openrouter.ai/keys

# ── LLM / AI ────────────────────────────────────────
VITE_OPENROUTER_API_KEY=sk-or-v1-your-key-here
VITE_LLM_MODEL=google/gemini-3-flash-preview
VITE_LLM_MAX_TOKENS=2048
VITE_LLM_TEMPERATURE=0.7
VITE_LLM_API_URL=https://openrouter.ai/api/v1/chat/completions

# ── Speech-to-Text ──────────────────────────────────
VITE_STT_MODEL=google/gemini-2.0-flash-exp:free
VITE_STT_LANG=pl

# ── Vision / Motion Detection ───────────────────────
VITE_VISION_OPENROUTER_MODEL=google/gemini-2.0-flash-exp:free
VITE_VISION_LOCAL_MODEL=llava:7b
VITE_MOTION_LLM_VERIFY_MODEL=anthropic/claude-haiku-4-5
VITE_BROWSE_LLM_MODEL=google/gemini-2.0-flash-001

# ── Network / Discovery ─────────────────────────────
VITE_DEFAULT_SUBNET=192.168.1

# ── Locale ──────────────────────────────────────────
VITE_LANGUAGE=pl
VITE_LOCALE=pl-PL

# ── Email (Tauri/Rust backend) ───────────────────────
# Local test: docker compose --profile mail up -d
# Then use: BROXEEN_SMTP_HOST=localhost BROXEEN_SMTP_PORT=1025 ...
BROXEEN_SMTP_HOST=localhost
BROXEEN_SMTP_PORT=1025
BROXEEN_SMTP_USER=test@broxeen.local
BROXEEN_SMTP_PASSWORD=test
BROXEEN_IMAP_HOST=localhost
BROXEEN_IMAP_PORT=1143
BROXEEN_EMAIL_FROM=broxeen@broxeen.local
BROXEEN_EMAIL_TLS=false

# ── Backend (Tauri/Rust) — secure, not exposed to frontend
OPENROUTER_API_KEY=sk-or-v1-your-key-here
LLM_MODEL=google/gemini-3-flash-preview
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.7

# ── Local LLM Configuration (Bielik-1.5B via Ollama) ───────────────────
LOCAL_LLM_MODEL=bielik:1.5b
LOCAL_LLM_MAX_TOKENS=300
LOCAL_LLM_TEMPERATURE=0.0
LOCAL_LLM_OLLAMA_URL=http://localhost
LOCAL_LLM_OLLAMA_PORT=11434

# ── NLP2CMD Integration ────────────────────────────────────
BROXEEN_NLP2CMD_ENABLED=1
LITELLM_MODEL=local/model
NLP2CMD_LLM_MODEL_PATH=models/Bielik-1.5B-v3.0-Instruct.Q8_0.gguf

# ── Backend-only LLM Models (fallback if VITE_* not set)
STT_MODEL=google/gemini-2.0-flash-exp:free
VISION_OPENROUTER_MODEL=google/gemini-2.0-flash-exp:free
VISION_LOCAL_MODEL=llava:7b
MOTION_LLM_VERIFY_MODEL=anthropic/claude-haiku-4-5
BROWSE_LLM_MODEL=google/gemini-2.0-flash-001
