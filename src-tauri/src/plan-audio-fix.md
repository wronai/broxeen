# ğŸ”Š Broxeen â€” Naprawa interfejsu audio (STT + TTS)

## Diagnoza problemu

### Root cause: WebKitGTK na Linux NIE obsÅ‚uguje Web Audio API

```
Frontend (WebKitGTK)
    â”œâ”€â”€ getUserMedia()     â†’ âŒ "not allowed by user agent"
    â”œâ”€â”€ SpeechRecognition  â†’ âŒ undefined
    â””â”€â”€ speechSynthesis    â†’ âŒ undefined
```

To nie jest bug Broxeen â€” to ograniczenie platformy. WebKitGTK:
- **Nie implementuje** `SpeechRecognition` / `SpeechSynthesis`
- **Blokuje** `getUserMedia` (wymaga custom build webkitgtk z WebRTC, co jest niepraktyczne)
- Issue: tauri-apps/wry#85, tauri-apps/tauri#8851, tauri-apps/tauri#12547

### Dlaczego obecny cloud STT nie dziaÅ‚a

TwÃ³j `useStt.ts` poprawnie wykrywa brak native STT i prÃ³buje cloud fallback, ALE:
1. `blobToWavBase64()` wymaga `MediaRecorder` + `getUserMedia` â†’ **blokowane przez WebKitGTK**
2. Nawet z kluczem OpenRouter, nagranie audio nie moÅ¼e siÄ™ rozpoczÄ…Ä‡

### Dlaczego TTS nie dziaÅ‚a

`useTts.ts` sprawdza `window.speechSynthesis` â†’ **undefined w WebKitGTK** â†’ hook ustawia `unsupported`

---

## RozwiÄ…zanie: Audio przez Rust (omijamy WebKitGTK)

```
PRZED (nie dziaÅ‚a):
  Mikrofon â†’ [WebKitGTK getUserMedia] âŒ â†’ JS â†’ Cloud STT
  Cloud TTS â†’ [WebKitGTK speechSynthesis] âŒ â†’ GÅ‚oÅ›nik

PO (dziaÅ‚a):
  Mikrofon â†’ [cpal / ALSA] âœ… â†’ Rust â†’ Cloud STT â†’ Frontend
  Tekst â†’ Rust â†’ [Piper TTS local] âœ… â†’ [rodio] â†’ GÅ‚oÅ›nik
```

### Stos technologiczny (darmowy, Å›rednia jakoÅ›Ä‡)

| Komponent | NarzÄ™dzie | JakoÅ›Ä‡ | Koszt | Offline? |
|-----------|-----------|--------|-------|----------|
| **STT** (speechâ†’text) | cpal + OpenRouter Whisper | â˜…â˜…â˜…â˜… | ~$0.006/min | âŒ cloud |
| **TTS** (textâ†’speech) | Piper TTS (neural ONNX) | â˜…â˜…â˜…â˜† | $0 | âœ… local |
| **TTS fallback** | espeak-ng | â˜…â˜…â˜†â˜† | $0 | âœ… local |
| **Audio capture** | cpal (Rust, ALSA) | â€” | $0 | âœ… |
| **Audio playback** | rodio (Rust, ALSA) | â€” | $0 | âœ… |

### Dlaczego Piper a nie espeak-ng

- **espeak-ng**: formulant synthesis, brzmi robotycznie, ale dziaÅ‚a wszÄ™dzie
- **Piper**: neural VITS models, brzmi naturalnie, <50MB model, ~5x realtime na CPU
- Polski gÅ‚os Piper: `pl_PL-darkman-medium` (~45MB) â€” przyzwoity mÄ™ski gÅ‚os
- Oba darmowe, oba offline, Piper znaczÄ…co lepszy

---

## Nowe/zmienione pliki

```
src-tauri/
â”œâ”€â”€ Cargo.toml                    # ZMIANA: +cpal, +rodio, +hound, +base64
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs                   # ZMIANA: +nowe komendy Tauri
â”‚   â”œâ”€â”€ audio_capture.rs          # NOWY: nagrywanie mikrofonu (cpal)
â”‚   â”œâ”€â”€ audio_playback.rs         # NOWY: odtwarzanie WAV (rodio)
â”‚   â”œâ”€â”€ tts_backend.rs            # NOWY: Piper TTS + espeak-ng fallback
â”‚   â”œâ”€â”€ stt.rs                    # ZMIANA: akceptuje WAV z audio_capture
â”‚   â””â”€â”€ llm.rs                    # bez zmian
src/
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useBackendStt.ts          # NOWY: STT przez Tauri commands
â”‚   â”œâ”€â”€ useBackendTts.ts          # NOWY: TTS przez Tauri commands
â”‚   â”œâ”€â”€ useStt.ts                 # ZMIANA: fallback â†’ useBackendStt
â”‚   â””â”€â”€ useTts.ts                 # ZMIANA: fallback â†’ useBackendTts
â”œâ”€â”€ components/
â”‚   â””â”€â”€ Chat.tsx                  # ZMIANA: unified mic toggle
â””â”€â”€ lib/
    â””â”€â”€ audioDevices.ts           # NOWY: lista urzÄ…dzeÅ„ audio z backendu
```

---

## KolejnoÅ›Ä‡ implementacji

| # | Zadanie | ZaleÅ¼noÅ›ci | Priorytet |
|---|---------|-----------|-----------|
| 1 | `Cargo.toml` â€” dodaj cpal, rodio, hound | â€” | ğŸ”´ |
| 2 | `audio_capture.rs` â€” nagrywanie WAV | cpal, hound | ğŸ”´ |
| 3 | `tts_backend.rs` â€” Piper + espeak | â€” | ğŸ”´ |
| 4 | `audio_playback.rs` â€” odtwarzanie WAV | rodio | ğŸ”´ |
| 5 | Komendy Tauri w `main.rs` | #2-4 | ğŸ”´ |
| 6 | `useBackendStt.ts` â€” frontend hook | #5 | ğŸ”´ |
| 7 | `useBackendTts.ts` â€” frontend hook | #5 | ğŸ”´ |
| 8 | `useStt.ts` / `useTts.ts` â€” fallback | #6-7 | ğŸŸ¡ |
| 9 | Instalacja Piper + model PL | â€” | ğŸ”´ |
| 10 | Testy e2e | #6-8 | ğŸŸ¢ |

---

## Wymagane zaleÅ¼noÅ›ci systemowe

```bash
# Linux (Ubuntu/Debian)
sudo apt install -y \
  libasound2-dev \          # ALSA â€” wymagane przez cpal
  espeak-ng \               # TTS fallback
  libespeak-ng-dev           # opcjonalne, jeÅ›li linkujesz

# Piper TTS (download binary + model)
mkdir -p ~/.local/share/broxeen/piper
cd ~/.local/share/broxeen/piper

# Binary
wget https://github.com/rhasspy/piper/releases/download/2023.11.14-2/piper_linux_x86_64.tar.gz
tar xzf piper_linux_x86_64.tar.gz

# Polski gÅ‚os (medium quality, ~45MB)
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/pl/pl_PL/darkman/medium/pl_PL-darkman-medium.onnx
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/pl/pl_PL/darkman/medium/pl_PL-darkman-medium.onnx.json
```

---

## Flow peÅ‚nego cyklu

### STT: Mikrofon â†’ Tekst

```
1. UÅ¼ytkownik klika ğŸ¤ w Chat
2. Frontend: invoke("stt_start_recording")
3. Rust (cpal): otwiera mikrofon ALSA, nagrywa do bufora
4. UÅ¼ytkownik klika ğŸ¤ ponownie (lub cisza 2s = auto-stop)
5. Frontend: invoke("stt_stop_and_transcribe")
6. Rust:
   a. Zamyka stream cpal
   b. Konwertuje bufor â†’ WAV (16kHz, mono, PCM16)
   c. Koduje WAV â†’ base64
   d. WysyÅ‚a do OpenRouter Whisper: POST /api/v1/audio/transcriptions
   e. Zwraca tekst transkrypcji
7. Frontend: wstawia tekst do input â†’ handleSubmit
```

### TTS: Tekst â†’ GÅ‚oÅ›nik

```
1. handleSubmit zwraca odpowiedÅº (browse/LLM/resolver)
2. Frontend: invoke("tts_speak", { text: "odpowiedÅº..." })
3. Rust (tts_backend):
   a. Sprawdza czy Piper dostÄ™pny â†’ jeÅ›li tak, uÅ¼yj Piper
   b. Fallback: espeak-ng
   c. Piper: echo "tekst" | piper --model pl_PL-darkman-medium --output_raw
   d. Odtwarza WAV przez rodio â†’ ALSA â†’ gÅ‚oÅ›nik
4. Frontend dostaje event "tts_done" / "tts_error"
```
