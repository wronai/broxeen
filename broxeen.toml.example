# broxeen.toml — Broxeen Vision v0.3
# Override any value with env vars: BROXEEN__CAMERA__URL etc.

[camera]
url       = "rtsp://admin:password@192.168.1.100:554/stream1"
camera_id = "front-door"

# Second camera: run a second instance with different camera_id and different db

[detector]
model_path           = "models/yolov8s.onnx"
confidence_threshold = 0.50
nms_threshold        = 0.45
input_size           = 640
use_openvino         = true    # Intel N5105: true | RPi5: false
intra_threads        = 2

[pipeline]
process_every_n_frames = 4     # N5105: 3-4 | RPi5: 5-6
bg_history             = 500
bg_var_threshold       = 40.0
min_activity_area      = 1500.0

[tracker]
iou_match_threshold = 0.30
max_age_frames      = 15
min_hits            = 3
crop_max_px         = 400
crops_per_track     = 3

[scene]
flush_interval_secs = 60    # LLM call every 60 seconds if objects detected
min_crops_for_llm   = 3     # skip LLM if fewer than 3 crops accumulated
ring_capacity       = 100
max_crops_per_batch = 10    # max images sent per LLM call

[database]
path = "monitoring.db"

[llm]
# ── Primary: OpenRouter ─────────────────────────────────────────────────────
# api_key = ""   ← set OPENROUTER_API_KEY env var instead (more secure)
openrouter_model = "google/gemini-2.0-flash-exp:free"

# Other good OpenRouter models:
# "google/gemini-flash-1.5"            fast, vision, cheap
# "meta-llama/llama-3.2-11b-vision-instruct:free"  free with vision
# "anthropic/claude-haiku-4-5-20251001"            if you have Anthropic credits
# "openai/gpt-4o-mini"                 OpenAI option

# ── Fallback: Local Ollama (must have llava model for vision) ───────────────
local_base_url = "http://localhost:11434/v1"
local_model    = "llava:7b"
# To install: ollama pull llava:7b

max_tokens           = 80
max_narrative_tokens = 400
